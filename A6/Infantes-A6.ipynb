{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A6.2 Tic Tac Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will run a number of comparisons between different neural networks trained through Q-learning to predict Q functions for Player X and for Player O in a simple Tic Tac Toe game.  \n",
    "\n",
    "All but one simple function is provided, so your effort will be in choosing the parameters for the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizers():\n",
    "\n",
    "    def __init__(self, all_weights):\n",
    "        '''all_weights is a vector of all of a neural networks weights concatenated into a one-dimensional vector'''\n",
    "        \n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        # The following initializations are only used by adam.\n",
    "        # Only initializing mt, vt, beta1t and beta2t here allows multiple calls to adam to handle training\n",
    "        # with multiple subsets (batches) of training data.\n",
    "        self.mt = np.zeros_like(all_weights)\n",
    "        self.vt = np.zeros_like(all_weights)\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.beta1t = 1  # was self.beta1\n",
    "        self.beta2t = 1  # was self.beta2\n",
    "\n",
    "        \n",
    "    def sgd(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, error_convert_f=None):\n",
    "        '''\n",
    "error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
    "gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error\n",
    "            with respect to each weight.\n",
    "error_convert_f: function that converts the standardized error from error_f to original T units.\n",
    "        '''\n",
    "\n",
    "        error_trace = []\n",
    "        epochs_per_print = n_epochs // 10\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            error = error_f(*fargs)\n",
    "            grad = gradient_f(*fargs)\n",
    "\n",
    "            # Update all weights using -= to modify their values in-place.\n",
    "            self.all_weights -= learning_rate * grad\n",
    "\n",
    "            if error_convert_f:\n",
    "                error = error_convert_f(error)\n",
    "            error_trace.append(error)\n",
    "\n",
    "        return error_trace\n",
    "\n",
    "    def adam(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, error_convert_f=None):\n",
    "        '''\n",
    "error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
    "gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error\n",
    "            with respect to each weight.\n",
    "error_convert_f: function that converts the standardized error from error_f to original T units.\n",
    "        '''\n",
    "        \n",
    "        # adam = Adaptive Moment Estimation\n",
    "\n",
    "        alpha = learning_rate  # learning rate called alpha in original paper on adam\n",
    "        epsilon = 1e-8\n",
    "        error_trace = []\n",
    "        epochs_per_print = n_epochs // 10\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            error = error_f(*fargs)\n",
    "            grad = gradient_f(*fargs)\n",
    "\n",
    "            # Finish Adam implementation here by updating\n",
    "            #   self.mt\n",
    "            #   self.vt\n",
    "            #   self.beta1t\n",
    "            #   self.beta2t\n",
    "            # and updating values of self.all_weights\n",
    "            \n",
    "            # mt = beta1 * mt + (1 - beta1) * gradE_W\n",
    "            gradE_W = learning_rate * grad\n",
    "            self.mt = self.beta1 * self.mt + (1 - self.beta1) * (gradE_W)\n",
    "            \n",
    "            # vt = beta2 * vt + (1 - beta2) * np.square(gradE_W)\n",
    "            self.vt = self.beta2 * self.vt + (1 - self.beta2) * np.square(gradE_W)\n",
    "            \n",
    "            # beta1t *= beta1\n",
    "            self.beta1t *= self.beta1\n",
    "            \n",
    "            # beta2t *= beta2\n",
    "            self.beta2t *= self.beta2\n",
    "            \n",
    "            # mhat = mt / (1 - beta1)\n",
    "            mhat = self.mt / (1 - self.beta1t)\n",
    "            \n",
    "            # vhat = vt / (1 - beta2)\n",
    "            vhat = self.vt / (1 - self.beta2t)\n",
    "            \n",
    "            # w -= rho * mhat / (np.sqrt(vhat) + epsilon)\n",
    "            # rho = learning rate?\n",
    "            self.all_weights -= learning_rate * mhat / (np.sqrt(vhat) + epsilon)\n",
    "        \n",
    "\n",
    "            if error_convert_f:\n",
    "                error = error_convert_f(error)\n",
    "            error_trace.append(error)\n",
    "\n",
    "\n",
    "        return error_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "\n",
    "    def __init__(self, n_inputs, n_hiddens_per_layer, n_outputs, activation_function=\"tanh\"):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        # Set self.n_hiddens_per_layer to [] if argument is 0, [], or [0]\n",
    "        if n_hiddens_per_layer == 0 or n_hiddens_per_layer == [] or n_hiddens_per_layer == [0]:\n",
    "            self.n_hiddens_per_layer = []\n",
    "        else:\n",
    "            self.n_hiddens_per_layer = n_hiddens_per_layer\n",
    "\n",
    "        # Initialize weights, by first building list of all weight matrix shapes.\n",
    "        n_in = n_inputs\n",
    "        shapes = []\n",
    "        for nh in self.n_hiddens_per_layer:\n",
    "            shapes.append((n_in + 1, nh))\n",
    "            n_in = nh\n",
    "        shapes.append((n_in + 1, n_outputs))\n",
    "\n",
    "        # self.all_weights:  vector of all weights\n",
    "        # self.Ws: list of weight matrices by layer\n",
    "        self.all_weights, self.Ws = self.make_weights_and_views(shapes)\n",
    "\n",
    "        # Define arrays to hold gradient values.\n",
    "        # One array for each W array with same shape.\n",
    "        self.all_gradients, self.dE_dWs = self.make_weights_and_views(shapes)\n",
    "\n",
    "        self.trained = False\n",
    "        self.total_epochs = 0\n",
    "        self.error_trace = []\n",
    "        self.Xmeans = None\n",
    "        self.Xstds = None\n",
    "        self.Tmeans = None\n",
    "        self.Tstds = None\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "\n",
    "    def make_weights_and_views(self, shapes):\n",
    "        # vector of all weights built by horizontally stacking flatenned matrices\n",
    "        # for each layer initialized with uniformly-distributed values.\n",
    "        all_weights = np.hstack([np.random.uniform(size=shape).flat / np.sqrt(shape[0])\n",
    "                                 for shape in shapes])\n",
    "        # Build list of views by reshaping corresponding elements from vector of all weights\n",
    "        # into correct shape for each layer.\n",
    "        views = []\n",
    "        start = 0\n",
    "        for shape in shapes:\n",
    "            size =shape[0] * shape[1]\n",
    "            views.append(all_weights[start:start + size].reshape(shape))\n",
    "            start += size\n",
    "        return all_weights, views\n",
    "\n",
    "\n",
    "    # Return string that shows how the constructor was called\n",
    "    def __repr__(self):\n",
    "        return f'NeuralNetwork({self.n_inputs}, {self.n_hiddens_per_layer}, {self.n_outputs})'\n",
    "\n",
    "\n",
    "    # Return string that is more informative to the user about the state of this neural network.\n",
    "    def __str__(self):\n",
    "        if self.trained:\n",
    "            return self.__repr__() + f' trained for {self.total_epochs} epochs, final training error {self.error_trace[-1]}'\n",
    "\n",
    "\n",
    "    def train(self, X, T, n_epochs, learning_rate, method='sgd'):\n",
    "        '''\n",
    "train: \n",
    "  X: n_samples x n_inputs matrix of input samples, one per row\n",
    "  T: n_samples x n_outputs matrix of target output values, one sample per row\n",
    "  n_epochs: number of passes to take through all samples updating weights each pass\n",
    "  learning_rate: factor controlling the step size of each update\n",
    "  method: is either 'sgd' or 'adam'\n",
    "        '''\n",
    "\n",
    "        # Setup standardization parameters\n",
    "        if self.Xmeans is None:\n",
    "            self.Xmeans = X.mean(axis=0)\n",
    "            self.Xstds = X.std(axis=0)\n",
    "            self.Xstds[self.Xstds == 0] = 1  # So we don't divide by zero when standardizing\n",
    "            self.Tmeans = T.mean(axis=0)\n",
    "            self.Tstds = T.std(axis=0)\n",
    "            \n",
    "        # Standardize X and T\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        T = (T - self.Tmeans) / self.Tstds\n",
    "\n",
    "        # Instantiate Optimizers object by giving it vector of all weights\n",
    "        optimizer = Optimizers(self.all_weights)\n",
    "\n",
    "        # Define function to convert value from error_f into error in original T units.\n",
    "        error_convert_f = lambda err: (np.sqrt(err) * self.Tstds)[0] # to scalar\n",
    "\n",
    "        if method == 'sgd':\n",
    "\n",
    "            for epoch in n_epochs:\n",
    "                error_trace = optimizer.sgd(self.error_f, self.gradient_f,\n",
    "                                            fargs=[X, T], n_epochs=epoch,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            error_convert_f=error_convert_f)\n",
    "\n",
    "        elif method == 'adam':\n",
    "\n",
    "            error_trace = optimizer.adam(self.error_f, self.gradient_f,\n",
    "                                         fargs=[X, T], n_epochs=n_epochs,\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         error_convert_f=error_convert_f)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"method must be 'sgd' or 'adam'\")\n",
    "        \n",
    "        self.error_trace = error_trace\n",
    "\n",
    "        # Return neural network object to allow applying other methods after training.\n",
    "        #  Example:    Y = nnet.train(X, T, 100, 0.01).use(X)\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def relu(self, s):\n",
    "        '''S is n_samples x n_units'''\n",
    "        Y = s.copy()\n",
    "        Y[Y < 0] = 0\n",
    "        return Y\n",
    "\n",
    "    def grad_relu(self, s):\n",
    "        '''S is n_samples x n_units'''\n",
    "        dY = s.copy()\n",
    "        return (dY > 0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        '''X assumed already standardized. Output returned as standardized.'''\n",
    "        self.Ys = [X]\n",
    "        for W in self.Ws[:-1]:\n",
    "            \n",
    "            if self.activation_function == 'tanh':\n",
    "                self.Ys.append(np.tanh(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
    "                \n",
    "            if self.activation_function == 'relu':\n",
    "                self.Ys.append(self.relu(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
    "                \n",
    "        last_W = self.Ws[-1]\n",
    "        self.Ys.append(self.Ys[-1] @ last_W[1:, :] + last_W[0:1, :])\n",
    "        return self.Ys\n",
    "\n",
    "    # Function to be minimized by optimizer method, mean squared error\n",
    "    def error_f(self, X, T):\n",
    "        Ys = self.forward_pass(X)\n",
    "        mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
    "        return mean_sq_error\n",
    "\n",
    "    # Gradient of function to be minimized for use by optimizer method\n",
    "    def gradient_f(self, X, T):\n",
    "        '''Assumes forward_pass just called with layer outputs in self.Ys.'''\n",
    "        error = T - self.Ys[-1]\n",
    "        n_samples = X.shape[0]\n",
    "        n_outputs = T.shape[1]\n",
    "        delta = - error / (n_samples * n_outputs)\n",
    "        n_layers = len(self.n_hiddens_per_layer) + 1\n",
    "        # Step backwards through the layers to back-propagate the error (delta)\n",
    "        for layeri in range(n_layers - 1, -1, -1):\n",
    "            # gradient of all but bias weights\n",
    "            self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
    "            # gradient of just the bias weights\n",
    "            self.dE_dWs[layeri][0:1, :] = np.sum(delta, 0)\n",
    "            \n",
    "            # Back-propagate this layer's delta to previous layer\n",
    "            if self.activation_function == 'tanh':\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
    "            \n",
    "            if self.activation_function == 'relu':\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * (self.grad_relu(self.Ys[layeri]))\n",
    "                \n",
    "        return self.all_gradients\n",
    "\n",
    "    def use(self, X):\n",
    "        '''X assumed to not be standardized. Return the unstandardized prediction'''\n",
    "        # Standardize X using Xmeans and Xstds in model\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        \n",
    "        '''\n",
    "        #print(len(self.all_weights), len(X), len(self.Ws))\n",
    "        # Predict output values using weights in model\n",
    "        #X = np.insert(X,0,1,axis=1)\n",
    "        # predict = X1 @ model['w']\n",
    "        #predict = X @ self.Ws\n",
    "        # Unstandardize the predicted output values using Tmeans and Tstds in model\n",
    "        #Y = predict * self.Tstds + self.Tmeans\n",
    "        # Return the unstandardized output values\n",
    "        #return Y\n",
    "        '''\n",
    "        Y = self.forward_pass(X)\n",
    "        T = Y[-1] * self.Tstds + self.Tmeans\n",
    "\n",
    "        # Y[1:]\n",
    "        return T\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state():\n",
    "    return np.array([0] * 9)\n",
    "\n",
    "def next_state(s, a, marker):  # s is a board, and a is an index into the cells of the board, marker is 1 or -1\n",
    "    s = s.copy()\n",
    "    s[a] = 1 if marker == 'X' else -1\n",
    "    return s\n",
    "\n",
    "def reinforcement(s):\n",
    "    if won('X', s):\n",
    "        return 1\n",
    "    if won('O', s):\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def won(player, s):\n",
    "    marker = 1 if player == 'X' else -1\n",
    "    combos = np.array((0,1,2, 3,4,5, 6,7,8, 0,3,6, 1,4,7, 2,5,8, 0,4,8, 2,4,6))\n",
    "    return np.any(np.all(marker == s[combos].reshape((-1, 3)), axis=1))\n",
    "\n",
    "def draw(s):\n",
    "    return sum(s == 0) == 0\n",
    "\n",
    "def valid_actions(state):\n",
    "    return np.where(state == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_sa(s, a):\n",
    "    return np.hstack((s, a)).reshape(1, -1)\n",
    "\n",
    "def other_player(player):\n",
    "    return 'X' if player == 'O' else 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(Qnet, state, epsilon):\n",
    "    \n",
    "    actions = valid_actions(state)\n",
    "    \n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Random Move\n",
    "        action = np.random.choice(actions)\n",
    "        \n",
    "    else:\n",
    "        # Greedy Move\n",
    "        np.random.shuffle(actions)\n",
    "        Qs = np.array([Qnet.use(stack_sa(state, a)) for a in actions])\n",
    "        action = actions[np.argmax(Qs)]\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples(Qnets, initial_state_f, next_state_f, reinforcement_f, epsilon):\n",
    "    '''Run one game'''\n",
    "    Samples = {'X': {'SA': [], 'R': [], 'Qn': []},\n",
    "               'O': {'SA': [], 'R': [], 'Qn': []}}\n",
    "\n",
    "    s = initial_state_f()\n",
    "    player = 'X'\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        a = epsilon_greedy(Qnets[player], s, epsilon)\n",
    "        sn = next_state_f(s, a, player)\n",
    "        r = reinforcement_f(sn)\n",
    "\n",
    "        Samples[player]['SA'].append(stack_sa(s, a))\n",
    "        Samples[player]['R'].append(r)   # r is with respect to X\n",
    "        Samples[player]['Qn'].append(0.0)  # fill in layer\n",
    "\n",
    "        if r != 0 or draw(sn):\n",
    "            Samples[other_player(player)]['R'][-1] = r  \n",
    "            break\n",
    "\n",
    "        s = sn\n",
    "        player = other_player(player)  # switch\n",
    "\n",
    "    for player in ['X', 'O']:\n",
    "        Samps = Samples[player]\n",
    "        Samps['SA'] = np.vstack(Samps['SA'])\n",
    "        Samps['R'] = np.array(Samps['R']).reshape(-1, 1)\n",
    "        Samps['Qn'] =  np.array(Samps['Qn']).reshape(-1 ,1)  # this statement added in A6.1\n",
    "\n",
    "    # Assign all Qn's, based on following state, but go every other state to do all X values,\n",
    "    ends_with_O = len(Samples['X']) > len(Samples['O'])\n",
    "    if ends_with_O:\n",
    "        # O wins\n",
    "        Samples['X']['Qn'][:-1] = Qnets['X'].use(Samples['X']['SA'][1:, :])\n",
    "        Samples['O']['Qn'][:-1] = Qnets['O'].use(Samples['O']['SA'][1:])\n",
    "    else:\n",
    "        # X wins or draw\n",
    "        Samples['X']['Qn'][:-1] = Qnets['X'].use(Samples['X']['SA'][1:])\n",
    "        Samples['O']['Qn'][:-1] = Qnets['O'].use(Samples['O']['SA'][1:])\n",
    "\n",
    "    for player in ['X', 'O']:\n",
    "        Samps = Samples[player]\n",
    "        Samps['Qn'] = np.array(Samps['Qn']).reshape(-1, 1)\n",
    "\n",
    "    return Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_status(outcomes, epsilons, n_trials, trial):\n",
    "    if trial == 0:\n",
    "        return\n",
    "    outcomes = np.array(outcomes)\n",
    "    n_per = 10\n",
    "    n_bins = (trial + 1) // n_per\n",
    "    if n_bins == 0:\n",
    "        return\n",
    "    outcome_rows = outcomes[:n_per * n_bins].reshape((-1, n_per))\n",
    "    outcome_rows = outcome_rows[:trial // n_per + 1, :]\n",
    "    avgs = np.mean(outcome_rows, axis=1)\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    xs = np.linspace(n_per, n_per * n_bins, len(avgs))\n",
    "    plt.plot(xs, avgs)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.xlabel('Games')\n",
    "    plt.ylabel('Mean of Outcomes') # \\n(0=draw, 1=X win, -1=O win)')\n",
    "    plt.title(f'Bins of {n_per:d} Games')\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(xs, np.sum(outcome_rows == -1, axis=1), 'r-', label='Losses')\n",
    "    plt.plot(xs, np.sum(outcome_rows == 0, axis=1), 'b-', label='Draws')\n",
    "    plt.plot(xs, np.sum(outcome_rows == 1, axis=1), 'g-', label='Wins')\n",
    "    plt.legend(loc='center')\n",
    "    plt.ylabel(f'Number of Games\\nin Bins of {n_per:d}')\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(epsilons[:trial])\n",
    "    plt.ylabel('$\\epsilon$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_standardization(Qnet, Xmeans, Xstds, Tmeans, Tstds):\n",
    "    Qnet.Xmeans = np.array(Xmeans)\n",
    "    Qnet.Xstds = np.array(Xstds)\n",
    "    Qnet.Tmeans = np.array(Tmeans)\n",
    "    Qnet.Tstds = np.array(Tstds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "def run(X_hidden_units_list_of_lists, O_hidden_units_list_of_lists, n_epochs_list, learning_rate_list, \n",
    "        repetitions=5, graphics=False):\n",
    "    \n",
    "    if graphics:\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        \n",
    "    n_trials = 8000         # number of repetitions of makeSamples-updateQ loop\n",
    "    \n",
    "    gamma = 1.0        # discount factor\n",
    "    final_epsilon = 0.01 # value of epsilon at end of simulation. Decay rate is calculated\n",
    "    epsilon_decay = np.exp(np.log(final_epsilon) / (n_trials)) # to produce this final value\n",
    "\n",
    "    results = []\n",
    "    for n_epochs in n_epochs_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            for X_nh in X_hidden_units_list_of_lists:\n",
    "                for O_nh in O_hidden_units_list_of_lists:\n",
    "                \n",
    "                    last_fifth_outcomes = []\n",
    "\n",
    "                    # RRn multiple experiments for these parameter values and average the results\n",
    "                    for rep in range(repetitions):\n",
    "                        \n",
    "                        print(rep + 1, end=' ')\n",
    "                        # Qnet for Player 'X'\n",
    "                        QnetX = NeuralNetwork(9 + 1, X_nh, 1)\n",
    "                        # Qnet for Player 'O'\n",
    "                        QnetO = NeuralNetwork(9 + 1, O_nh, 1)\n",
    "                        Qnets = {'X': QnetX, 'O': QnetO}\n",
    "\n",
    "                        # Inputs are 9 TTT cells plus 1 action\n",
    "                        setup_standardization(QnetX, [0] * 10, [1] * 10, [0], [1])\n",
    "                        setup_standardization(QnetO, [0] * 10, [1] * 10, [0], [1])\n",
    "\n",
    "                        epsilon = 1         # initial epsilon value\n",
    "                        outcomes = []\n",
    "                        epsilon_trace = []\n",
    "\n",
    "                        # Train for n_trials\n",
    "                        for trial in range(n_trials):\n",
    "\n",
    "                            Samples = make_samples(Qnets, initial_state, next_state, reinforcement, epsilon)\n",
    "\n",
    "                            Samps = Samples['X']\n",
    "                            SA = Samps['SA']\n",
    "                            R = Samps['R']\n",
    "                            Qn = Samps['Qn']\n",
    "                            T = R + gamma * Qn\n",
    "                            Qnets['X'].train(SA, T, n_epochs, learning_rate, method='sgd')\n",
    "\n",
    "                            Samps = Samples['O']\n",
    "                            SA = Samps['SA']\n",
    "                            R = - Samps['R']  # r is with respect to X, so negate it\n",
    "                            Qn = Samps['Qn']\n",
    "                            T = R + gamma * Qn\n",
    "                            Qnets['O'].train(SA, T, n_epochs, learning_rate, method='sgd')\n",
    "\n",
    "                            outcomes.append(Samples['X']['R'][-1])\n",
    "                            epsilon_trace.append(epsilon)\n",
    "\n",
    "                            epsilon *= epsilon_decay\n",
    "                            \n",
    "                            if graphics and (trial + 1 == n_trials or trial % (n_trials / 20) == 0):\n",
    "                                plt.clf()\n",
    "                                plot_status(outcomes, epsilon_trace, n_trials, trial)\n",
    "                                clear_output(wait=True)\n",
    "                                display(fig)\n",
    "\n",
    "                        # For each repetition collect the mean of the outcome for the final fifth games\n",
    "                        last_fifth_outcomes.append(np.mean(outcomes[-n_trials // 5:]))\n",
    "                        print(f'{last_fifth_outcomes[-1]:.1f},', end=' ')\n",
    "                        \n",
    "                    results.append([X_nh, O_nh, n_epochs, learning_rate, np.mean(last_fifth_outcomes)])\n",
    "                    print(results[-1])\n",
    "                    \n",
    "    if graphics:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    return pandas.DataFrame(results, columns=('X_nh', 'O_nh', 'n_epochs', 'lr', 'last_fifth_outcomes')), Qnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for X winning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy a version of `myresult()` into next cell that contains a network architecture with which X can win the game.  If you cannot get X to win the game, put one of the strategies you tried here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[], [], [5], [0.001], 0.9404999999999999]\n",
      "1 0.9, 2 1.0, 3 1.0, 4 0.9, 5 0.9, [[], [100, 20], [5], [0.001], 0.947625]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[], [20, 20, 20], [5], [0.001], 0.9390000000000001]\n",
      "1 0.8, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[10, 10], [], [5], [0.001], 0.90425]\n",
      "1 0.9, 2 1.0, 3 0.9, 4 0.9, 5 1.0, [[10, 10], [100, 20], [5], [0.001], 0.94575]\n",
      "1 0.9, 2 0.8, 3 0.9, 4 0.9, 5 0.9, [[10, 10], [20, 20, 20], [5], [0.001], 0.9094999999999999]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 1.0, 5 0.9, [[10, 20], [], [5], [0.001], 0.93675]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 1.0, 5 1.0, [[10, 20], [100, 20], [5], [0.001], 0.9525]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 1.0, 5 0.9, [[10, 20], [20, 20, 20], [5], [0.001], 0.94825]\n",
      "1 0.9, 2 1.0, 3 0.9, 4 0.9, 5 0.9, [[], [], [5], [0.01], 0.9400000000000001]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[], [100, 20], [5], [0.01], 0.9337499999999999]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.6, 5 0.9, [[], [20, 20, 20], [5], [0.01], 0.8463750000000001]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 1.0, 5 1.0, [[10, 10], [], [5], [0.01], 0.9588750000000001]\n",
      "1 0.9, 2 1.0, 3 0.8, 4 0.8, 5 0.8, [[10, 10], [100, 20], [5], [0.01], 0.8445]\n",
      "1 1.0, 2 0.9, 3 1.0, 4 1.0, 5 1.0, [[10, 10], [20, 20, 20], [5], [0.01], 0.9571250000000001]\n",
      "1 1.0, 2 0.9, 3 1.0, 4 1.0, 5 0.9, [[10, 20], [], [5], [0.01], 0.9588750000000001]\n",
      "1 0.9, 2 0.9, 3 0.8, 4 0.7, 5 0.8, [[10, 20], [100, 20], [5], [0.01], 0.8484999999999999]\n",
      "1 1.0, 2 0.8, 3 1.0, 4 1.0, 5 1.0, [[10, 20], [20, 20, 20], [5], [0.01], 0.936625]\n",
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-90d984758462>:171: RuntimeWarning: overflow encountered in multiply\n",
      "  delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
      "<ipython-input-3-90d984758462>:151: RuntimeWarning: overflow encountered in square\n",
      "  mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
      "<ipython-input-3-90d984758462>:171: RuntimeWarning: overflow encountered in matmul\n",
      "  delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
      "<ipython-input-3-90d984758462>:171: RuntimeWarning: invalid value encountered in multiply\n",
      "  delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
      "<ipython-input-3-90d984758462>:165: RuntimeWarning: overflow encountered in matmul\n",
      "  self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
      "<ipython-input-3-90d984758462>:165: RuntimeWarning: invalid value encountered in matmul\n",
      "  self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
      "<ipython-input-2-4c41ffc0fa23>:36: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.all_weights -= learning_rate * grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3, 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/latest/lib/python3.8/site-packages/numpy/core/_methods.py:151: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "<ipython-input-3-90d984758462>:145: RuntimeWarning: invalid value encountered in matmul\n",
      "  self.Ys.append(self.Ys[-1] @ last_W[1:, :] + last_W[0:1, :])\n",
      "<ipython-input-3-90d984758462>:151: RuntimeWarning: invalid value encountered in subtract\n",
      "  mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
      "<ipython-input-3-90d984758462>:157: RuntimeWarning: invalid value encountered in subtract\n",
      "  error = T - self.Ys[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3, 3 0.3, 4 0.3, 5 0.3, [[], [], [5], [0.1], 0.28625]\n",
      "1 0.2, 2 0.1, 3 0.1, 4 0.1, 5 0.1, [[], [100, 20], [5], [0.1], 0.12137500000000001]\n",
      "1 -0.0, 2 0.1, 3 -0.1, 4 0.1, 5 -0.0, [[], [20, 20, 20], [5], [0.1], 0.018000000000000002]\n",
      "1 0.6, 2 0.6, 3 0.7, 4 0.7, 5 0.6, [[10, 10], [], [5], [0.1], 0.65225]\n",
      "1 0.9, 2 0.9, 3 1.0, 4 0.8, 5 0.9, [[10, 10], [100, 20], [5], [0.1], 0.8943749999999999]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 0.7, 5 0.6, [[10, 10], [20, 20, 20], [5], [0.1], 0.8234999999999999]\n",
      "1 0.7, 2 0.6, 3 0.6, 4 0.7, 5 0.6, [[10, 20], [], [5], [0.1], 0.627375]\n",
      "1 0.8, 2 0.7, 3 0.9, 4 0.7, 5 0.9, [[10, 20], [100, 20], [5], [0.1], 0.80425]\n",
      "1 0.7, 2 0.9, 3 0.7, 4 1.0, 5 0.9, [[10, 20], [20, 20, 20], [5], [0.1], 0.817]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[], [], [10], [0.001], 0.9355]\n",
      "1 0.2, 2 0.4, 3 0.7, 4 0.9, 5 0.2, [[], [100, 20], [10], [0.001], 0.492375]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.8, 5 0.9, [[], [20, 20, 20], [10], [0.001], 0.9101250000000001]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 0.9, 5 1.0, [[10, 10], [], [10], [0.001], 0.946125]\n",
      "1 0.2, 2 0.3, 3 0.7, 4 0.9, 5 0.4, [[10, 10], [100, 20], [10], [0.001], 0.529625]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[10, 10], [20, 20, 20], [10], [0.001], 0.9366249999999999]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 0.9, 5 0.9, [[10, 20], [], [10], [0.001], 0.9272499999999999]\n",
      "1 1.0, 2 0.9, 3 0.9, 4 1.0, 5 0.6, [[10, 20], [100, 20], [10], [0.001], 0.8821249999999999]\n",
      "1 0.9, 2 0.9, 3 0.9, 4 "
     ]
    }
   ],
   "source": [
    "def myresult1():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[], [10, 10], [10,20]],\n",
    "                        O_hidden_units_list_of_lists=[[], [100, 20], [20, 20, 20]],\n",
    "                        n_epochs_list=[[5],[10],[20]],\n",
    "                        learning_rate_list=[[0.001],[0.01],[0.1]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time1 = time.time()\n",
    "\n",
    "result1 = myresult1()\n",
    "\n",
    "print(f'Took {(time.time() - start_time1) / 60.0:.1f} minutes.')\n",
    "\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myresult2():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[10], [10], [10]],\n",
    "                        O_hidden_units_list_of_lists=[[], [100, 10], [20,10]],\n",
    "                        n_epochs_list=[[5],[15],[25]],\n",
    "                        learning_rate_list=[[0.01],[0.001],[0.1]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "start_time2 = time.time()\n",
    "\n",
    "result2 = myresult2()\n",
    "\n",
    "print(f'Took {(time.time() - start_time2) / 60.0:.1f} minutes.')\n",
    "\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myresult3():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[], [100, 10], [5]],\n",
    "                        O_hidden_units_list_of_lists=[[], [10,100], [50,10]],\n",
    "                        n_epochs_list=[[3],[6],[9]],\n",
    "                        learning_rate_list=[[0.1],[0.001],[0.01]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "start_time3 = time.time()\n",
    "\n",
    "result3 = myresult3()\n",
    "\n",
    "print(f'Took {(time.time() - start_time3) / 60.0:.1f} minutes.')\n",
    "\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could not get X to win the game. Partly due to the expirements taking very long to complete. Also, my computer would crash at times. Therefore, it was difficult to gather enough information to get the job done correctly. The issue might've been selecting the size of each layer for the four hyperparameters to be too large. Also, the implementaion of NeuralNetworks need to be tweaked to better aid the expirments. The tweaks however aren't very clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for O winning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy a version of `myresult()` into next cell that contains a network architecture with which O can win the game.  If you cannot get O to win the game, put one of the strategies you tried here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myresult4():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[], [100, 40], [40, 40, 40]],\n",
    "                        O_hidden_units_list_of_lists=[[], [10, 10], [10,20]],\n",
    "                        n_epochs_list=[[5],[10],[15]],\n",
    "                        learning_rate_list=[[0.001],[0.01],[0.1]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "start_time4 = time.time()\n",
    "\n",
    "result4 = myresult4()\n",
    "\n",
    "print(f'Took {(time.time() - start_time4) / 60.0:.1f} minutes.')\n",
    "\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myresult5():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[], [100, 10], [20,10]],\n",
    "                        O_hidden_units_list_of_lists=[[100], [100], [100]],\n",
    "                        n_epochs_list=[[3],[6],[9]],\n",
    "                        learning_rate_list=[[0.01],[0.0001],[0.1]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "start_time5 = time.time()\n",
    "\n",
    "result5 = myresult5()\n",
    "\n",
    "print(f'Took {(time.time() - start_time5) / 60.0:.1f} minutes.')\n",
    "\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myresult6():\n",
    "    result, Qnets = run(X_hidden_units_list_of_lists=[[], [10,50], [50,10]],\n",
    "                        O_hidden_units_list_of_lists=[[], [100, 10], [50]],\n",
    "                        n_epochs_list=[[10],[20],[30]],\n",
    "                        learning_rate_list=[[0.1],[0.001],[0.0001]], \n",
    "                        repetitions=5, graphics=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "start_time6 = time.time()\n",
    "\n",
    "result6 = myresult6()\n",
    "\n",
    "print(f'Took {(time.time() - start_time6) / 60.0:.1f} minutes.')\n",
    "\n",
    "result6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could not get O to win the game because I had the epoch numbers too large when I was running my expirements. Thus it lead to extremely slow completion times. I learne my mistakes and corrected them. Then, things ran a lot faster but not fast enough so the number of expirements I could run was very minimal thus leading to an inability to properly get O to win the game. There maybe exist a possiblity that I also implemented my Neural Networks incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*There is no grader script for this assignment.*  The entirety of your grade is based on trying the required number of experiments and presenting your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "For 1 point of extra credit do the following steps.\n",
    "\n",
    "1. Call `run` using your best parameter values and for 1 repetition.\n",
    "2. Create four boards for which it is `X`'s turn. Using the returned `Qnets` print a display of the Q values generated by `Qnets['X']` in a 3 x 3 table corresponding to the tic tac toe board, for each of these four boards.\n",
    "3. Create four boards for which it is `O`'s turn. Using the returned `Qnets` print a display of the Q values generated by `Qnets['O']` in a 3 x 3 table corresponding to the tic tac toe board, for these four boards.\n",
    "4. Discuss the values.  Do they make sense?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
